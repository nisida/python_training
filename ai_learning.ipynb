{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e443a2db",
   "metadata": {},
   "source": [
    "# 目標\n",
    "\n",
    "## 機械学習の基礎を理解して、独自で基本的な学習モデルのコードを実装できるようになる。\n",
    "\n",
    "# 学習内容\n",
    "\n",
    "## - AIとは何か\n",
    "## - 機械学習の基本原理とは\n",
    "## - 機械学習を構成する要素\n",
    "## - 機械学習モデルとは\n",
    "## - TensorFlowとPythonによるautoencoderの実装\n",
    "## - 画像分類技術の基礎\n",
    "## - TensorFlowとPythonによる画像分類の実装\n",
    "## - スパムメール分類\n",
    "## - 強化学習の基礎\n",
    "## - 迷路探索アルゴリズムの実装(各自)\n",
    "## - 生成AIの使い方（プロンプト）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c50c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\"\"\"Train My Autoencoder Model\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D  \n",
    "\n",
    "random.seed(42)  # @UndefinedVariable\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "\"\"\"Autoencoder Simples Model\n",
    "https://elix-tech.github.io/ja/2016/07/17/autoencoder.html\n",
    "参考論文 : https://arxiv.org/pdf/1812.11262.pdf\n",
    "[我々はロバストな予測のためのオートエンコーダーベースの残差ディープネットワークを提案する]\n",
    "\"\"\"\n",
    "    \n",
    "    # load mnist data\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, [-1, x_train.shape[1] * x_train.shape[2]])\n",
    "x_test  = np.reshape(x_test, [-1, x_test.shape[1] * x_test.shape[2]])\n",
    "\n",
    "# encode\n",
    "encoding_dim = 32\n",
    "input_img    = Input(shape=(x_train.shape[1], ), name = \"autoencoder\" + \"_input\")\n",
    "encoded      = Dense(encoding_dim, activation='relu')(input_img)\n",
    "encoded      = Flatten(name='flatten_e1')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation='relu')(encoded)\n",
    "encoded      = Flatten(name='flatten_e2')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation='relu')(encoded)\n",
    "encoded      = Flatten(name='flatten_e3')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation='relu')(encoded)\n",
    "# decode\n",
    "decoded      = Dense(784, activation='sigmoid')(encoded)\n",
    "decoded      = Flatten(name='flatten_d1')(decoded)\n",
    "decoded      = Dense(784, activation='sigmoid')(decoded)\n",
    "decoded      = Flatten(name='flatten_d2')(decoded)\n",
    "decoded      = Dense(784, activation='sigmoid')(decoded)\n",
    "decoded      = Flatten(name='flatten_d3')(decoded)\n",
    "decoded      = Dense(784, activation='sigmoid')(decoded)\n",
    "    \n",
    "autoencoder  = Model(input_img, decoded)\n",
    "\n",
    "# Opt\n",
    "opt = Adam(lr=1e-4)\n",
    "#autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') <- NG\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "    \n",
    "hist = autoencoder.fit(x_train, x_train, epochs=80, batch_size=128, shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "def results_draw(x_test, decode_imgs) :\n",
    "      \n",
    "    \"\"\"Draw Autoencoder Results\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "      \n",
    "    # 何個表示するか\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # オリジナルのテスト画像を表示\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # 変換された画像を表示\n",
    "        ax = plt.subplot(2, n, i+1+n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    #plt.savefig(\"autoencoder_results.png\")\n",
    "    plt.show()\n",
    "\n",
    "results_draw(x_test, decoded_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb309065",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.decorder = tf.keras.Sequential([layers.Dense(tf.math.reduce_prod(shape), activation='sigmoid'), \n",
    "                                     layers.Reshape(shape)], name = \"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a79d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# 絶対値の範囲が 有限なもの\n",
    "activations_type0 = [\n",
    "    \"sigmoid\",\n",
    "    \"tanh\",\n",
    "    \"hard_sigmoid\",\n",
    "    \"softsign\",\n",
    "]\n",
    "\n",
    "# 絶対値の範囲に上限がないもの\n",
    "activations_type1 = [\n",
    "    \"elu\",\n",
    "    \"selu\",\n",
    "    \"softplus\",\n",
    "    \"relu\",\n",
    "    \"linear\",\n",
    "]\n",
    "\n",
    "x = np.linspace(-5, 5, 101).reshape(-1, 1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "for i, activations in enumerate([activations_type0, activations_type1]) :\n",
    "    ax = fig.add_subplot(2, 1, i + 1)\n",
    "    for activation_str in activations:\n",
    "        model = Sequential()\n",
    "        model.add(Activation(activation_str, input_shape=(1,)))\n",
    "        y = model.predict(x).ravel()\n",
    "        ax.plot(x, y, label=activation_str)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a16ec",
   "metadata": {},
   "source": [
    "## 再急降下法\n",
    "\n",
    "多くの場合、学習の問題は、与えられた評価関数を最適とするようなパラメータを求める問題として定式\n",
    "化されます。従って、学習のためには、その最適化問題を解くための手法が必要になります。最適化手法に\n",
    "は、簡単なものから高速性や安定性のために工夫した複雑手法まで、多くの手法がありますが、ここでは、\n",
    "最も簡単な最適化手法のひとつである最急降下法と呼ばれる最適化手法の基本的な考え方について理解し\n",
    "そのプログラムを作ってみることにします\n",
    "\n",
    "### 問題\n",
    "あるパラメータa の良さの評価尺度が以下のような２次の関数  \n",
    "\n",
    " $$ f(a) = (a - 1.0) ^ 2 $$\n",
    "\n",
    " で与えられたとします。このとき、この評価関数が最小となるパラメータ a の(最適解) を求めなさい。  \n",
    "\n",
    " $$ 微分 :     \\frac{\\partial f}{\\partial a} = 2(a - 1.0) $$\n",
    "\n",
    "### 再急降下法\n",
    "最急降下法 最急降下法は、ある適当な初期値(初期パラメータ) からはじめて、その値を繰り返し更新する\n",
    "(修正する) ことにより、最適なパラメータの値を求める方法(繰り返し最適化手法) の最も基本的で\n",
    "単な方法です。\n",
    "\n",
    "$$ 更新式 :  \\alpha^{(k + 1)} = \\alpha^{(k)} - 2\\alpha(a - 1.0) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sympy as sy\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# SymPy Plotting Backends (SPB)\n",
    "#from spb import plot, plot_implicit\n",
    "from spb import plot\n",
    "\n",
    "# グラフを SVG で Notebook にインライン表示\n",
    "# これは試し\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# おまじない\n",
    "sy.init_printing()\n",
    "\n",
    "# π，ネイピア数，虚数単位\n",
    "from sympy import pi, E, I\n",
    "\n",
    "\n",
    "a = sy.symbols('a')\n",
    "\n",
    "func = lambda x: (x -1.0) ** 2\n",
    "display(Math(r\" func = %s\" % sy.latex(func(a))))\n",
    "\n",
    "dfunc = sy.diff(func(a), a)\n",
    "display(Math(r\" \\frac{d}{da} func = %s\" % sy.latex(dfunc)))\n",
    "\n",
    "print(\"value = {}\".format(sy.solve(dfunc)))\n",
    "\n",
    "plot(func(a), (a, -2, 4), line_color='r')\n",
    "\n",
    "def main() :\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    alpha = 0.1\n",
    "    rng = np.random.default_rng()\n",
    "    _a = 100 * (rng.random() - 0.5)\n",
    "    \n",
    "    for _ in range(100) :\n",
    "        _a = _a - alpha * dfunc.subs(a, _a)\n",
    "        \n",
    "    return _a\n",
    "\n",
    "\n",
    "print(\" result = \", main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"autoencoderを実装する\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# 学習データを用意する\n",
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "# データを正規化する\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32') / 255.\n",
    "\n",
    "print(\"x_train.shape = \", x_train.shape)\n",
    "print(\"x_test.shape  = \", x_test.shape)\n",
    "\n",
    "# 潜在空間の次元数\n",
    "latent_dim   = 64\n",
    "# targetの次元数\n",
    "target_shape = x_train.shape[1:]\n",
    "\n",
    "# batch size, epoch\n",
    "batch_size = 128\n",
    "epochs     = 10\n",
    "\n",
    "# modelの定義\n",
    "model = Sequential(name = \"autoencoder\")\n",
    "encoder_1 = Flatten(input_shape = target_shape, name = \"encoder_1\")\n",
    "encoder_2 = Dense(latent_dim, activation = 'relu', name = \"encoder_2\")\n",
    "model.add(encoder_1)\n",
    "model.add(encoder_2)\n",
    "#decorder_1 = Dense(tf.math.reduce_prod(target_shape), activation = 'sigmoid', name = \"decoder_1\")\n",
    "decorder_1 = Dense(target_shape[0] * target_shape[1], activation = 'sigmoid', name = \"decoder_1\")\n",
    "decorder_2 = Reshape(target_shape, name = \"decoder_2\")\n",
    "model.add(decorder_1)\n",
    "model.add(decorder_2)\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer = optimizers.Adam(), loss = losses.MeanSquaredError())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 学習\n",
    "history = model.fit(x_train, x_train, \n",
    "                    epochs  = epochs, batch_size = batch_size, \n",
    "                    shuffle = True,  validation_data = (x_test, x_test))\n",
    "\n",
    "# 結果を評価する\n",
    "decoded_imgs = model.predict(x_test)\n",
    "print(\"decoded_imgs.shape = \", decoded_imgs.shape)\n",
    "\n",
    "def results_draw(x_test, decode_imgs) :\n",
    "      \n",
    "    \"\"\"Draw Autoencoder Results\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "      \n",
    "    # 何個表示するか\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # オリジナルのテスト画像を表示\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # 変換された画像を表示\n",
    "        ax = plt.subplot(2, n, i+1+n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "results_draw(x_test, decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e566203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (60000, 28, 28, 1)\n",
      "x_test.shape  =  (10000, 28, 28, 1)\n",
      "target_shape =  (28, 28, 1)\n",
      "Model: \"cnn_autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_2 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " encoder_3 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " decoder_1 (Conv2DTranspose  (None, 14, 14, 64)        36928     \n",
      " )                                                               \n",
      "                                                                 \n",
      " decoder_2 (Conv2DTranspose  (None, 28, 28, 32)        18464     \n",
      " )                                                               \n",
      "                                                                 \n",
      " decoder_3 (Conv2D)          (None, 28, 28, 1)         289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74497 (291.00 KB)\n",
      "Trainable params: 74497 (291.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"CNN autoencoderを実装する\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, Input\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# 学習データを用意する\n",
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "# データを正規化する\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "print(\"x_train.shape = \", x_train.shape)\n",
    "print(\"x_test.shape  = \", x_test.shape)\n",
    "\n",
    "# targetの次元数\n",
    "target_shape = x_train.shape[1:]\n",
    "print(\"target_shape = \", target_shape)\n",
    "\n",
    "# batch size, epoch\n",
    "batch_size = 128\n",
    "epochs     = 10\n",
    "\n",
    "# modelの定義\n",
    "model = Sequential(name = \"cnn_autoencoder\")\n",
    "encoder_1 = Input(shape = target_shape, name = \"encoder_1\")\n",
    "encoder_2 = Conv2D(32, kernel_size = (3, 3), activation = 'relu', padding = 'same', strides = 2, name = \"encoder_2\")\n",
    "encoded_3 = Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same', strides = 2, name = \"encoder_3\")\n",
    "model.add(encoder_1)\n",
    "model.add(encoder_2)\n",
    "model.add(encoded_3)\n",
    "decorder_1 = Conv2DTranspose(64, kernel_size = (3, 3), activation = 'relu', padding = 'same', strides = 2, name = \"decoder_1\")\n",
    "decorder_2 = Conv2DTranspose(32, kernel_size = (3, 3), activation = 'relu', padding = 'same', strides = 2, name = \"decoder_2\")\n",
    "decorder_3 = Conv2D(1, kernel_size = (3, 3), activation = 'sigmoid', padding = 'same', name = \"decoder_3\")\n",
    "model.add(decorder_1)\n",
    "model.add(decorder_2)\n",
    "model.add(decorder_3)\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer = optimizers.Adam(), loss = losses.BinaryCrossentropy())\n",
    "\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
